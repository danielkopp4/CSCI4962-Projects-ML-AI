{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your project, you will pick a dataset (time-series) and an associated problem that can be\n",
    "solved via sequence models. You must describe why you need sequence models to solve this\n",
    "problem. Include a link to the dataset source. Next, you should pick an RNN framework that you\n",
    "would use to solve this problem (This framework can be in TensorFlow, PyTorch or any other\n",
    "Python Package). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the famous Shakespeare's plays dataset containing Shakespeare's works (https://www.kaggle.com/datasets/kingburrito666/shakespeare-plays?resource=download, only the txt file). Only sequence models would work on this dataset as its text and it requires positional awareness to predict the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding, LSTM, GRU\n",
    "from tensorflow.keras import Sequential\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique tokens: 8643\n",
      "random line of data: 'see riot and dishonour stain the brow'\n",
      "tokenized version: [322, 369, 30, 370, 371, 16, 372, 0]\n",
      "reconstructed version from tokens: 'see riot and dishonour stain the brow '\n"
     ]
    }
   ],
   "source": [
    "# upon inspecting the data it is evident that there are many kinds of punctuation\n",
    "# we would like a word like \"hi!\"\" to equal tokens of \"hi\" + \"!\" rather\n",
    "# than having \"hi\" \"hi!\" be completely different tokens\n",
    "# such is the case for all other punctuation\n",
    "# one punctuating character that appears specific to these works \n",
    "# is \"--\" which has been added to the special punctuation characters \n",
    "\n",
    "\n",
    "# returns to_add_tokens, word without punctuation\n",
    "punctuation = [\",\", \".\", \"!\", \":\", \";\", \")\", \"]\", \"--\", \"(\", \"[\"]\n",
    "def account_for_punct(word):\n",
    "    to_add_tokens = []\n",
    "    # check for (, only character that occurs at the beginning\n",
    "    # others will be at the end\n",
    "\n",
    "    # if these are the only characters do not check for suffix punctuation\n",
    "    if word == \"[\" or word == \"(\":\n",
    "        return [punctuation.index(word) + 2], \"\"\n",
    "\n",
    "    if \"(\" == word[0] or \"[\" == word[0]:\n",
    "        to_add_tokens.append(punctuation.index(\"(\") + 2)\n",
    "        word = word[1:]\n",
    "\n",
    "\n",
    "    # check for end of character punctuation\n",
    "    end_char = word[-1]\n",
    "    if end_char in punctuation:\n",
    "        to_add_tokens.append(punctuation.index(end_char) + 2)\n",
    "        word = word[:-1]\n",
    "\n",
    "    return to_add_tokens, word\n",
    "\n",
    "    \n",
    "\n",
    "# takes in raw text as array of strings\n",
    "def get_token_mappings(inpt: List[str]):\n",
    "    counter = 2 + len(punctuation) # reserved for punctuation\n",
    "    str_to_token = {\"\\n\" : 0, \"\": 1} \n",
    "    token_to_str = {0: \"\\n\", 1: \"\"}\n",
    "\n",
    "    # add the punctuation in\n",
    "    for i, punct in enumerate(punctuation):\n",
    "        token_to_str[i + 2] = punct\n",
    "        str_to_token[punct] = i + 2\n",
    "\n",
    "    # go line by line and add newline char to end of token input\n",
    "    tokenized = []\n",
    "    for line in inpt:\n",
    "        # remove \" character\n",
    "        line = line.replace('\"', \"\").replace(\"\\n\", \"\").lower()\n",
    "        # word based tokenization\n",
    "        words = line.split(\" \")\n",
    "\n",
    "        for word in words:\n",
    "            # skip token\n",
    "            if word == \"\":\n",
    "                tokenized.append(1)\n",
    "                continue\n",
    "\n",
    "            # process punctuation, gets added before word\n",
    "            # likely not the best strategy but should suffice\n",
    "            # for this use case\n",
    "            to_add_tokens, word = account_for_punct(word)\n",
    "            for token in to_add_tokens:\n",
    "                tokenized.append(token)\n",
    "\n",
    "            # add word if not in vocab\n",
    "            if word not in str_to_token:\n",
    "                str_to_token[word] = counter\n",
    "                token_to_str[counter] = word\n",
    "                counter += 1\n",
    "\n",
    "            # tokenize processed word\n",
    "            tokenized.append(str_to_token[word])\n",
    "\n",
    "        # add newline token\n",
    "        tokenized.append(0)\n",
    "\n",
    "    # convert to np array \n",
    "    tokenized = np.array(tokenized).reshape(len(tokenized), 1)\n",
    "    return str_to_token, token_to_str, counter, tokenized\n",
    "\n",
    "def tokenize(str_to_token, string):\n",
    "    tokenized = []\n",
    "    for line in string.split(\"\\n\"):\n",
    "        line = line.replace('\"', \"\").replace(\"\\n\", \"\").lower()\n",
    "        words = line.split(\" \")\n",
    "        for word in words:\n",
    "            if word == \"\":\n",
    "                tokenized.append(1)\n",
    "                continue\n",
    "\n",
    "            to_add_tokens, word = account_for_punct(word)\n",
    "            for token in to_add_tokens:\n",
    "                tokenized.append(token)\n",
    "\n",
    "            tokenized.append(str_to_token[word])\n",
    "\n",
    "        tokenized.append(0)\n",
    "\n",
    "    return np.array(tokenized).reshape(len(tokenized), 1)\n",
    "\n",
    "\n",
    "def lookup(token_to_str, tokens):\n",
    "    if type(tokens) == np.ndarray:\n",
    "        tokens = tokens.flatten()\n",
    "\n",
    "    string = []\n",
    "\n",
    "    prev_punct = None\n",
    "\n",
    "    for token in tokens:\n",
    "        if token == 0:\n",
    "            string.append(\"\\n\")\n",
    "        elif token == 1:\n",
    "            string.append(\"\")\n",
    "        elif token < 2 + len(punctuation):\n",
    "            punct = punctuation[token - 2]\n",
    "            if not prev_punct:\n",
    "                prev_punct = punct\n",
    "            else:\n",
    "                if type(prev_punct) == list:\n",
    "                    prev_punct = prev_punct[0]\n",
    "                    \n",
    "                prev_punct = [prev_punct, punct]\n",
    "        else:\n",
    "            word = token_to_str[token]\n",
    "            if prev_punct:\n",
    "                if type(prev_punct) == list:\n",
    "                    word = prev_punct[0] + word + prev_punct[1]\n",
    "                elif prev_punct == \"[\" or prev_punct == \"(\":\n",
    "                    word = prev_punct + word\n",
    "                else:\n",
    "                    word = word + prev_punct\n",
    "\n",
    "                prev_punct = None\n",
    "            string.append(word)\n",
    "\n",
    "    return \" \".join(string)\n",
    "            \n",
    "\n",
    "with open(\"alllines.txt\") as file:\n",
    "    data = file.readlines()\n",
    "data = data[:10000]\n",
    "\n",
    "str_to_token, token_to_str, n_tokens, tokenized = get_token_mappings(data)\n",
    "print(f\"number of unique tokens: {n_tokens}\")\n",
    "random_line_number = int(np.random.rand() * len(data))\n",
    "random_line = data[random_line_number].replace('\"', \"\").replace(\"\\n\", \"\").lower()\n",
    "print(f\"random line of data: '{random_line}'\")\n",
    "print(f\"tokenized version: {tokenize(str_to_token, random_line)}\")\n",
    "reconstructed = lookup(token_to_str, tokenize(str_to_token, random_line)).replace(\"\\n\", \"\")\n",
    "print(f\"reconstructed version from tokens: '{reconstructed}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_tokens(token_data, n_tokens):\n",
    "    output = np.zeros((len(token_data), n_tokens))\n",
    "    for i, token in enumerate(token_data):\n",
    "        output[i][token] = 1\n",
    "\n",
    "    return output\n",
    "\n",
    "def reverse_one_hot_encode(one_hot_encoded):\n",
    "    tokens = []\n",
    "    for one_hot in one_hot_encoded:\n",
    "        tokens.append(np.argmax(one_hot))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "split_index = int(len(tokenized) * split)\n",
    "data_train = tokenized[:split_index]\n",
    "data_test = tokenized[split_index:]\n",
    "\n",
    "data_train = data_train[:-1], one_hot_encode_tokens(data_train[1:], n_tokens) # y is shifted 1 over\n",
    "data_test = data_test[:-1], one_hot_encode_tokens(data_test[1:], n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (60 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 (30 points): \n",
    "Implement your RNN either using an existing framework OR you can\n",
    "implement your own RNN cell structure. In either case, describe the structure of your\n",
    "RNN and the activation functions you are using for each time step and in the output\n",
    "layer. Define a metric you will use to measure the performance of your model (NOTE:\n",
    "Performance should be measured both for the validation set and the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 1, 64)             553152    \n",
      "                                                                 \n",
      " simple_rnn_18 (SimpleRNN)   (None, 1, 64)             8256      \n",
      "                                                                 \n",
      " simple_rnn_19 (SimpleRNN)   (None, 1, 128)            24704     \n",
      "                                                                 \n",
      " simple_rnn_20 (SimpleRNN)   (None, 512)               328192    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8643)              4433859   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,348,163\n",
      "Trainable params: 5,348,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = [64, 64, 128, 512]\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(n_tokens, input_length=1, output_dim=units[0]),\n",
    "    SimpleRNN(units[1], activation=\"relu\", kernel_initializer=\"he_uniform\", return_sequences=True),\n",
    "    SimpleRNN(units[2], activation=\"relu\", kernel_initializer=\"he_uniform\", return_sequences=True),\n",
    "    SimpleRNN(units[3], activation=\"relu\", kernel_initializer=\"he_uniform\"),\n",
    "    Dense(n_tokens, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2494/2494 [==============================] - 105s 42ms/step - loss: 5.8809 - val_loss: 5.7368\n",
      "Epoch 2/2\n",
      "2494/2494 [==============================] - 85s 34ms/step - loss: 5.3172 - val_loss: 5.7641\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(*data_train, validation_data=data_test, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc5b4229b10>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text input: and bootless 'tis to tell you we will go: \n",
      " therefore we meet not now. then let me hear \n",
      " of you, my gentle cousin westmoreland, \n",
      " what yesternight our council did decree \n",
      " in forwarding this dear expedience. \n",
      " my liege, this haste was hot in question, \n",
      " and many limits of the charge set down \n",
      " but yesternight: when all athwart there came \n",
      " a post from wales loaden with heavy news, \n",
      " whose worst was, that the noble mortimer, \n",
      " leading the men of herefordshire to \n",
      "\n",
      "predicted for each word:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "',the, ,be, me \\n \\n ,me, \\n me, \\n \\n ,lord, \\n ,lord, \\n \\n \\n \\n ,the, \\n ,me, \\n ,lord, \\n \\n ,the, lord \\n \\n \\n \\n \\n ,me, \\n i \\n \\n is \\n \\n ,the, \\n \\n the lord, \\n ,lord, ,lord, \\n \\n \\n \\n ,the,'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_pred = model(data_train[0][300:400])\n",
    "tokens = reverse_one_hot_encode(one_hot_pred)\n",
    "print(\"text input:\", lookup(token_to_str, data_train[0][300:400].flatten()), \"\\n\\npredicted for each word:\")\n",
    "lookup(token_to_str, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (35 points): \n",
    "Update your network from part 1 with first an LSTM and then a GRU\n",
    "based cell structure (You can treat both as 2 separate implementations). Re-do the\n",
    "training and performance evaluation. What are the major differences you notice? Why\n",
    "do you think those differences exist between the 3 implementations (basic RNN, LSTM\n",
    "and GRU)?\n",
    "Note: In part 1 and 2, you must perform sufficient data-visualization, pre-processing\n",
    "and/or feature-engineering if needed. The overall performance visualization of the loss\n",
    "function should also be provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 64)          553152    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 64)          33024     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 128)         98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 512)               1312768   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8643)              4433859   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,431,619\n",
      "Trainable params: 6,431,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = [64, 64, 128, 512]\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(n_tokens, output_dim=units[0]),\n",
    "    LSTM(units[1], activation=\"relu\", kernel_initializer=\"he_uniform\", return_sequences=True),\n",
    "    LSTM(units[2], activation=\"relu\", kernel_initializer=\"he_uniform\", return_sequences=True),\n",
    "    LSTM(units[3], activation=\"relu\", kernel_initializer=\"he_uniform\"),\n",
    "    Dense(n_tokens, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3118/3118 [==============================] - 151s 47ms/step - loss: 6.0431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5a4afe650>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(*data_train, validation_data=data_test, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_pred = model(data_train[0][300:400])\n",
    "tokens = reverse_one_hot_encode(one_hot_pred)\n",
    "print(\"text input:\", lookup(token_to_str, data_train[0][300:400].flatten()), \"\\n\\npredicted for each word:\")\n",
    "lookup(token_to_str, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 64)          553152    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 64)          24960     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, None, 128)         74496     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 512)               986112    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8643)              4433859   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,072,579\n",
      "Trainable params: 6,072,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = [64, 64, 128, 512]\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(n_tokens, output_dim=units[0]),\n",
    "    GRU(units[1], activation=\"relu\", kernel_initializer=\"he_uniform\", return_sequences=True),\n",
    "    GRU(units[2], activation=\"relu\", kernel_initializer=\"he_uniform\", return_sequences=True),\n",
    "    GRU(units[3], activation=\"relu\", kernel_initializer=\"he_uniform\"),\n",
    "    Dense(n_tokens, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3118/3118 [==============================] - 133s 42ms/step - loss: 5.9439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5a6e727d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(*data_train, validation_data=data_test, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_pred = model(data_train[0][300:400])\n",
    "tokens = reverse_one_hot_encode(one_hot_pred)\n",
    "print(\"text input:\", lookup(token_to_str, data_train[0][300:400].flatten()), \"\\n\\npredicted for each word:\")\n",
    "lookup(token_to_str, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 (10 points): \n",
    "Can you use the traditional feed-forward network to solve the same\n",
    "problem. Why or why not? (Hint: Can time series data be converted to usual features\n",
    "that can be used as input to a feed-forward network?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would not be a complete solution but it would be possible to pass a window of the input, however, this would be memory intensive and would still not capture the full context of the input as any context outside of the window is lost to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (25 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, use any of the pre-trained word embeddings. The Wor2vec embedding link\n",
    "provided with the lecture notes can be useful to get started. Write your own code/function that \n",
    "uses these embeddings and outputs cosine similarity and a dissimilarity score for any 2 pair of\n",
    "words (read as user input). The dissimilarity score should be defined by you. You either can\n",
    "have your own idea of a dissimilarity score or refer to literature (cite the paper you used). In\n",
    "either case clearly describe how this score helps determine the dissimilarity between 2 words.\n",
    "\n",
    "Note: Dissimilarity measure has been an important metric for recommender systems trying to\n",
    "introduce ‘Novelty and Diversity’ in assortments (as opposed to only accuracy). You might find\n",
    "different metrics of dissimilarity in recommender system’s literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to read local cache '/Users/danielkopp/gensim-data/information.json' during fallback, connect to the Internet and retry",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/danielkopp/gensim-data/information.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y2/_kzfb30s4xqbkpvb3kdm47c00000gn/T/ipykernel_47820/3409412162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \"\"\"\n\u001b[1;32m    489\u001b[0m     \u001b[0m_create_base_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incorrect model/corpus name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_get_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0minformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0mcorpora\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'corpora'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36minfo\u001b[0;34m(name, show_only_latest, name_only)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0minformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    222\u001b[0m         raise ValueError(\n\u001b[1;32m    223\u001b[0m             \u001b[0;34m'unable to read local cache %r during fallback, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;34m'connect to the Internet and retry'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcache_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unable to read local cache '/Users/danielkopp/gensim-data/information.json' during fallback, connect to the Internet and retry"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "corpus = api.load('text8')\n",
    "model = Word2Vec(corpus)\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return a.dot(b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# similarity and distance metrics are inverses of each other\n",
    "# this is usually a multiplicative relationship\n",
    "# ie. cosine distance would be 1 / cosine similarity\n",
    "# therefore distances are the same as dissimilarity\n",
    "# one very general distance metric is the minkowski distance\n",
    "# this is a generalization of the euclidian, manhattan \n",
    "# and chebyshev distances\n",
    "# p = 1,   manhattan\n",
    "# p = 2,   euclidian\n",
    "# p = inf, chebyshev\n",
    "def minkowski(a, b, p):\n",
    "    return np.power(np.sum(np.power(np.linalg.norm(a - b),p)), 1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = input(\"enter the first word: \")\n",
    "print(f\"the first word is '{word1}'\")\n",
    "\n",
    "word2 = input(\"enter the second word: \")\n",
    "print(f\"the first word is '{word2}'\")\n",
    "\n",
    "vec1, vec2 = model[word1], model[word2]\n",
    "\n",
    "print(f\"cosine similarity = {cosine_sim(vec1, vec2)}\")\n",
    "print(f\"manhattan distance = {minkowski(vec1, vec2, 1)}\")\n",
    "print(f\"euclidan distance = {minkowski(vec1, vec2, 2)}\")\n",
    "print(f\"chebychev distance = {minkowski(vec1, vec2, np.inf)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
